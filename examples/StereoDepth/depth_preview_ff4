#!/usr/bin/env python3


from pathlib import Path
import cv2
import depthai as dai
import argparse
import numpy as np
import cv2


#calibJsonFile = str((Path(__file__).parent / Path('../models/depthai_calib.json')).resolve().absolute())
calibJsonFile = "/home/han9/depthai/resources/14442C1061C9E6D600_03_05_24_14_34.json"
parser = argparse.ArgumentParser()
parser.add_argument('calibJsonFile', nargs='?', help="Path to calibration file in json", default=calibJsonFile)
args = parser.parse_args()

# calibData = dai.CalibrationHandler(args.calibJsonFile)
# Closer-in minimum depth, disparity range is doubled (from 95 to 190):
extendedDisparity = True
# Better accuracy for longer distance, fractional disparity 32-levels:
subpixel = False
# Better handling for occlusions:
lrCheck = True

enableRectified = True

# Create pipeline
pipeline = dai.Pipeline()

# Define sources and outputs
left = pipeline.create(dai.node.MonoCamera)
right = pipeline.create(dai.node.MonoCamera)

# Create stereo
stereo = pipeline.create(dai.node.StereoDepth)
xoutDepth = pipeline.create(dai.node.XLinkOut)
xoutDepth.setStreamName("disparity")

# Properties
left.setResolution(dai.MonoCameraProperties.SensorResolution.THE_800_P)
left.setBoardSocket(dai.CameraBoardSocket.CAM_B)
left.setCamera("CAMB-2L")
left.setFps(100)
right.setResolution(dai.MonoCameraProperties.SensorResolution.THE_800_P)
right.setBoardSocket(dai.CameraBoardSocket.CAM_C)
right.setCamera("CAMC-2L")
right.setFps(100)

stereo.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)
stereo.initialConfig.setMedianFilter(dai.MedianFilter.KERNEL_7x7)
stereo.setLeftRightCheck(lrCheck)
stereo.setExtendedDisparity(extendedDisparity)
stereo.setSubpixel(subpixel)


# Linking
left.out.link(stereo.left)
right.out.link(stereo.right)
if enableRectified:
    xoutRectR = pipeline.create(dai.node.XLinkOut)
    xoutRectL= pipeline.create(dai.node.XLinkOut)
    xoutRectR.setStreamName("rectifiedRight")
    xoutRectL.setStreamName("rectifiedLeft")
    stereo.rectifiedLeft.link(xoutRectL.input)
    stereo.rectifiedRight.link(xoutRectR.input)
stereo.disparity.link(xoutDepth.input)

maxDisp = stereo.initialConfig.getMaxDisparity()

# Connect to device and start pipeline
with dai.Device(pipeline) as device:
    while not device.isClosed():
        queueNames = device.getQueueEvents()
        for q in queueNames:
            message = device.getOutputQueue(q).get()
            # Display arrived frames
            if type(message) == dai.ImgFrame:
                frame = message.getCvFrame()
                if 'disparity' in q:
                    disp = (frame * (255.0 / maxDisp)).astype(np.uint8)
                    disp = cv2.applyColorMap(disp, cv2.COLORMAP_JET)
                    cv2.imshow(q, disp)
                else:
                    cv2.imshow(q, frame)
        if cv2.waitKey(1) == ord('q'):
            break
            
